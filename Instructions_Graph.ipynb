{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66283859",
   "metadata": {},
   "source": [
    "## How to Run Spark on Windows\n",
    "1. Download Spark [v3.2.0] and save file contents to `C:/BigData/spark`\n",
    "  - `spark-submit --version`\n",
    "  - https://spark.apache.org/downloads.html\n",
    "2. Download winutils from `hadoop-3.0.0/bin` and add it to `C:/BigData/hadoop/bin`\n",
    "  - https://github.com/steveloughran/winutils\n",
    "3. Download Java Version 8 [v1.8.0_311]\n",
    "  - `java --version`\n",
    "4. Add to environment variables\n",
    "  - `HADOOP_HOME` = `C:/BigData/hadoop`\n",
    "  - `SPARK_HOME` = `C:/BigData/spark`\n",
    "  - `SPARK_LOCAL_DIRS` = `C:/BigData/tmp`\n",
    "  - `SPARK_LOCAL_HOSTNAME` = `localhost`\n",
    "  - `SPARK_LOCAL_IP` = `127.0.0.1`\n",
    "  - `PYSPARK_DRIVER_PYTHON` = `jupyter`\n",
    "  - `PYSPARK_DRIVER_PYTHON_OPTS` = `notebook`\n",
    "5. Download pyspark and graphframes [graphframes==0.8.2]\n",
    "  - Install PySpark: `pip install pyspark`\n",
    "  - Install GraphFrames: `pip install graphframes`\n",
    "  - Check version: `pip freeze > requirements.txt`\n",
    "6. Download scala [v2.12.14]\n",
    "  - Download version 2 --> SBT Version\n",
    "  - Run `sbt console` in current directory to install \n",
    "  - Check global scalaVersion: `sbt scalaVersion`\n",
    "  - Check pyspark scalaVersion: `spark-submit --version`\n",
    "  - https://www.scala-lang.org/download/scala2.html\n",
    "\n",
    "- Create new dir `C:/BigData/spark`\n",
    "- Create new dir `C:/BigData/hadoop`\n",
    "- Create new dir `C:/BigData/tmp`\n",
    "- Modify permissions to `C:/User/tmp` to be modified by everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5ea1c5-b590-42cf-99c1-902482fd09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphFrame(v:[id: string, latitude: float ... 2 more fields], e:[src: string, dst: string ... 2 more fields])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from graphframes import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import os\n",
    "os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'notebook'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell\"\n",
    ")\n",
    "\n",
    "from graphframes import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.appName(\"fun\").master(\"local[*]\").config(\"spark.driver.bindAddress\", \"localhost\").getOrCreate()\n",
    "\n",
    "# GraphFrame from the CSV files\n",
    "def create_transport_graph():\n",
    "    node_fields = [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"latitude\", FloatType(), True),\n",
    "        StructField(\"longitude\", FloatType(), True),\n",
    "        StructField(\"population\", IntegerType(), True)\n",
    "    ]\n",
    "    nodes = spark.read.csv(\"data/transport-nodes.csv\", header=True,\n",
    "    schema=StructType(node_fields))\n",
    "    rels = spark.read.csv(\"data/transport-relationships.csv\", header=True)\n",
    "    reversed_rels = (rels.withColumn(\"newSrc\", rels.dst)\n",
    "        .withColumn(\"newDst\", rels.src)\n",
    "        .drop(\"dst\", \"src\")\n",
    "        .withColumnRenamed(\"newSrc\", \"src\")\n",
    "        .withColumnRenamed(\"newDst\", \"dst\")\n",
    "        .select(\"src\", \"dst\", \"relationship\", \"cost\"))\n",
    "    relationships = rels.union(reversed_rels)\n",
    "\n",
    "    return GraphFrame(nodes, relationships)\n",
    "g = create_transport_graph()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61f6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+---+\n",
      "| id|  name|firstname|age|\n",
      "+---+------+---------+---+\n",
      "|  1|Carter|  Derrick| 50|\n",
      "|  2|   May|  Derrick| 26|\n",
      "|  3| Mills|     Jeff| 80|\n",
      "|  4|  Hood|   Robert| 65|\n",
      "|  5| Banks|     Mike| 93|\n",
      "| 98|  Berg|      Tim| 28|\n",
      "| 99|  Page|    Allan| 16|\n",
      "+---+------+---------+---+\n",
      "\n",
      "+---+---+-------+\n",
      "|src|dst|   type|\n",
      "+---+---+-------+\n",
      "|  1|  2| friend|\n",
      "|  2|  1| friend|\n",
      "|  3|  1| friend|\n",
      "|  1|  3| friend|\n",
      "|  2|  3|follows|\n",
      "|  3|  4| friend|\n",
      "|  4|  3| friend|\n",
      "|  5|  3| friend|\n",
      "|  3|  5| friend|\n",
      "|  4|  5|follows|\n",
      "| 98| 99| friend|\n",
      "| 99| 98| friend|\n",
      "+---+---+-------+\n",
      "\n",
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|  1|     4|\n",
      "|  2|     3|\n",
      "|  3|     7|\n",
      "|  4|     3|\n",
      "|  5|     3|\n",
      "| 98|     2|\n",
      "| 99|     2|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'notebook'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell\"\n",
    ")\n",
    "\n",
    "from graphframes import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.appName(\"fun\").master(\"local[*]\").config(\"spark.driver.bindAddress\", \"localhost\").getOrCreate()\n",
    "\n",
    "vertices = spark.createDataFrame([('1', 'Carter', 'Derrick', 50), \n",
    "                                  ('2', 'May', 'Derrick', 26),\n",
    "                                 ('3', 'Mills', 'Jeff', 80),\n",
    "                                  ('4', 'Hood', 'Robert', 65),\n",
    "                                  ('5', 'Banks', 'Mike', 93),\n",
    "                                 ('98', 'Berg', 'Tim', 28),\n",
    "                                 ('99', 'Page', 'Allan', 16)],\n",
    "                                 ['id', 'name', 'firstname', 'age'])\n",
    "edges = spark.createDataFrame([('1', '2', 'friend'), \n",
    "                               ('2', '1', 'friend'),\n",
    "                              ('3', '1', 'friend'),\n",
    "                              ('1', '3', 'friend'),\n",
    "                               ('2', '3', 'follows'),\n",
    "                               ('3', '4', 'friend'),\n",
    "                               ('4', '3', 'friend'),\n",
    "                               ('5', '3', 'friend'),\n",
    "                               ('3', '5', 'friend'),\n",
    "                               ('4', '5', 'follows'),\n",
    "                              ('98', '99', 'friend'),\n",
    "                              ('99', '98', 'friend')],\n",
    "                              ['src', 'dst', 'type'])\n",
    "g = GraphFrame(vertices, edges)\n",
    "## Take a look at the DataFrames\n",
    "g.vertices.show()\n",
    "g.edges.show()\n",
    "## Check the number of edges of each vertex\n",
    "g.degrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a5758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
